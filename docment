ollama: ollama.com/search
cmd中: ollama run 模型名称     （运行模型）
ollama api调用: http://localhost:11434/v1

openai库基础：

    {"role": "assistant", "content": "我是你的助手。"},
    {"role": "user", "content": "你是谁"}

    message中的assistant相当于提交给ai的历史记录


LangChain:
    1、pip install langchain langchain-community langchain-ollama dashscope chromadb -i https://pypi.tuna.tsinghua.edu.cn/simple

        langchain:核心包
        langchain-community:社区支持包(千问模型需要这个包)
        langchain-ollama:Ollama支持包
        dashscope:阿里云通义千问的python SDK
        chromadb:轻量向量数据库

    2、通义千问qwen-max是llms， qwen3-max是chat， 输出qwen-max用的是chunk, 输出qwen3-max用的是chunk.content
    for chunk in model.stream(input=message):
        print(chunk, end='', flush=True)
        print(chunk.content, end='', flush=True)

    3、三类模型 llm、chat、
